{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e359b47f-d9ab-480c-a020-b8656843d2c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/takuto/data-musicalization-new/data-musicalization-venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from FileLoader import FileLoader\n",
    "from DisplayHistogram import DisplayHistogram\n",
    "from RandomDataPicker import RandomDataPicker\n",
    "from ConvertElementToAspect import ConvertElementToAspect\n",
    "from PromptExporter import PromptExporter\n",
    "from CreateChordsAndMelody import CreateChordsAndMelody\n",
    "from ValenceArousalToEmotion import ValenceArousalToEmotion\n",
    "from MusicGenFromMelody import MusicGenFromMelody\n",
    "from MusicGenerater import MusicGenerater"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae5be2f",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3053429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File loaded successfully: ../data/weather_test_data_202505.csv \n",
      "elements in loaded data: ['Unnamed: 0', 'sunlight', 'temperature', 'precipitation', 'weather']\n",
      "rows in data: 9\n"
     ]
    }
   ],
   "source": [
    "# specify file name here\n",
    "weather_data_filepath = \"../data/weather_test_data_202505.csv\"\n",
    "\n",
    "file_loader = FileLoader(weather_data_filepath) # create instance\n",
    "\n",
    "# load data from specified csv file\n",
    "loaded_data = file_loader.load_csv()\n",
    "# print(loaded_data)\n",
    "\n",
    "elements = file_loader.get_elements()\n",
    "rows = file_loader.get_rows()\n",
    "print(f\"elements in loaded data: {elements}\\nrows in data: {rows}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9519c8ab",
   "metadata": {},
   "source": [
    "## Visualization of Loaded Data (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b97df2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display_histogram = DisplayHistogram(loaded_data)\n",
    "# display_histogram.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9cfe05",
   "metadata": {},
   "source": [
    "## Randomly Pick Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29655bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_data_picker = RandomDataPicker(loaded_data)\n",
    "# random_df = random_data_picker.get_random_data_samples(6, exclude_duplicate='precipitation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b99978e",
   "metadata": {},
   "source": [
    "## Assign Data Parameters to Musical Aspects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b167611e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'precipitation' [20, 0] is mapped to 'valence [0, 100]' (inverted)\n",
      "[90, 90, 90, 0, 0, 0, -100, -100, -100]\n",
      "'temperature' [20, 10] is mapped to 'arousal [0, 100]'\n",
      "[10, 50, 100, 10, 50, 100, 10, 50, 100]\n",
      "['extremely contentment', 'extremely happy and joyful', 'extremely happy and joyful', 'extremely happy and joyful', 'happy and joyful', 'extremely happy and joyful', 'extremely sad', 'extremely angery or fearful', 'extremely angery or fearful']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "convert_element_to_aspect = ConvertElementToAspect(loaded_data)\n",
    "\n",
    "# convert valence [-100, 100]\n",
    "valence_array = convert_element_to_aspect.convert_element_to_valence('precipitation', 20, 0, isInverted=True)\n",
    "print(valence_array)\n",
    "# convert valence [0, 100]\n",
    "arousal_array = convert_element_to_aspect.convert_element_to_arousal('temperature', 20, 10)\n",
    "print(arousal_array)\n",
    "\n",
    "e = ValenceArousalToEmotion(valence_array, arousal_array)\n",
    "emotion_array = e.convert_valencea_arousal_to_emotion()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d473a185",
   "metadata": {},
   "source": [
    "## Generate Music from Prompt\n",
    "### Generate Melody Files (MIDI and WAV Files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce3c1227",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# c = CreateChordsAndMelody()\n",
    "# c.create_midi_and_wav(valence_array, arousal_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6386a414",
   "metadata": {},
   "source": [
    "### Generate Music Based on Melody Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe1cf3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/bin/ffmpeg\n",
      "-------- Generating --------\n",
      "prompt: Electronic music, extremely contentment\n",
      "melody: melody_4_val0_aro10.wav\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/takuto/data-musicalization-new/data-musicalization-venv/lib/python3.9/site-packages/audiocraft/models/musicgen.py:80: UserWarning: MusicGen pretrained model relying on deprecated checkpoint mapping. Please use full pre-trained id instead: facebook/musicgen-melody\n",
      "  warnings.warn(\n",
      "/Users/takuto/data-musicalization-new/data-musicalization-venv/lib/python3.9/site-packages/torch/nn/utils/weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    },
    {
     "ename": "LibsndfileError",
     "evalue": "Error opening 'melody_4_val0_aro10.wav': System error.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLibsndfileError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m wav_files \u001b[38;5;241m=\u001b[39m [f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(output_dir) \u001b[38;5;28;01mif\u001b[39;00m f\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.wav\u001b[39m\u001b[38;5;124m'\u001b[39m)] \u001b[38;5;66;03m# iterate for all wav files in specified directory\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, wav_path \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(wav_files):\n\u001b[0;32m---> 11\u001b[0m     \u001b[43mmg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmusic_gen_from_melody\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwav_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmusic_genre\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m, \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43memotion_array\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# mg.music_gen_from_melody(melody_path=\"../data/output/20250508_053837/melody_6_val0_aro100.wav\", description=f\"{music_genre}, {emotion_array[5]}\", idx)\u001b[39;00m\n",
      "File \u001b[0;32m~/data-musicalization-new/src/MusicGenFromMelody.py:28\u001b[0m, in \u001b[0;36mMusicGenFromMelody.music_gen_from_melody\u001b[0;34m(self, melody_path, description, idx)\u001b[0m\n\u001b[1;32m     25\u001b[0m model \u001b[38;5;241m=\u001b[39m MusicGen\u001b[38;5;241m.\u001b[39mget_pretrained(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmelody\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     26\u001b[0m model\u001b[38;5;241m.\u001b[39mset_generation_params(duration\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mduration)\n\u001b[0;32m---> 28\u001b[0m melody, sr \u001b[38;5;241m=\u001b[39m \u001b[43mtorchaudio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmelody_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# generates using the melody from the given audio and the provided descriptions.\u001b[39;00m\n\u001b[1;32m     30\u001b[0m wav \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgenerate_with_chroma([description], melody, sr)\n",
      "File \u001b[0;32m~/data-musicalization-new/data-musicalization-venv/lib/python3.9/site-packages/torchaudio/_backend/utils.py:203\u001b[0m, in \u001b[0;36mget_load_func.<locals>.load\u001b[0;34m(uri, frame_offset, num_frames, normalize, channels_first, format, buffer_size, backend)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load audio data from source.\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \n\u001b[1;32m    128\u001b[0m \u001b[38;5;124;03mBy default (``normalize=True``, ``channels_first=True``), this function returns Tensor with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;124;03m        `[channel, time]` else `[time, channel]`.\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    202\u001b[0m backend \u001b[38;5;241m=\u001b[39m dispatcher(uri, \u001b[38;5;28mformat\u001b[39m, backend)\n\u001b[0;32m--> 203\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannels_first\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/data-musicalization-new/data-musicalization-venv/lib/python3.9/site-packages/torchaudio/_backend/soundfile.py:26\u001b[0m, in \u001b[0;36mSoundfileBackend.load\u001b[0;34m(uri, frame_offset, num_frames, normalize, channels_first, format, buffer_size)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload\u001b[39m(\n\u001b[1;32m     18\u001b[0m     uri: Union[BinaryIO, \u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m     buffer_size: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4096\u001b[39m,\n\u001b[1;32m     25\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor, \u001b[38;5;28mint\u001b[39m]:\n\u001b[0;32m---> 26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msoundfile_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannels_first\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/data-musicalization-new/data-musicalization-venv/lib/python3.9/site-packages/torchaudio/_backend/soundfile_backend.py:221\u001b[0m, in \u001b[0;36mload\u001b[0;34m(filepath, frame_offset, num_frames, normalize, channels_first, format)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;129m@_requires_soundfile\u001b[39m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload\u001b[39m(\n\u001b[1;32m    141\u001b[0m     filepath: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28mformat\u001b[39m: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    147\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor, \u001b[38;5;28mint\u001b[39m]:\n\u001b[1;32m    148\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load audio data from file.\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \n\u001b[1;32m    150\u001b[0m \u001b[38;5;124;03m    Note:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;124;03m            `[channel, time]` else `[time, channel]`.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 221\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43msoundfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSoundFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file_:\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m file_\u001b[38;5;241m.\u001b[39mformat \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWAV\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m normalize:\n\u001b[1;32m    223\u001b[0m             dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/data-musicalization-new/data-musicalization-venv/lib/python3.9/site-packages/soundfile.py:690\u001b[0m, in \u001b[0;36mSoundFile.__init__\u001b[0;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd, compression_level, bitrate_mode)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bitrate_mode \u001b[38;5;241m=\u001b[39m bitrate_mode\n\u001b[1;32m    688\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info \u001b[38;5;241m=\u001b[39m _create_info_struct(file, mode, samplerate, channels,\n\u001b[1;32m    689\u001b[0m                                  \u001b[38;5;28mformat\u001b[39m, subtype, endian)\n\u001b[0;32m--> 690\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode_int\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosefd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mset\u001b[39m(mode)\u001b[38;5;241m.\u001b[39missuperset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseekable():\n\u001b[1;32m    692\u001b[0m     \u001b[38;5;66;03m# Move write position to 0 (like in Python file objects)\u001b[39;00m\n\u001b[1;32m    693\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/data-musicalization-new/data-musicalization-venv/lib/python3.9/site-packages/soundfile.py:1265\u001b[0m, in \u001b[0;36mSoundFile._open\u001b[0;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[1;32m   1262\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file_ptr \u001b[38;5;241m==\u001b[39m _ffi\u001b[38;5;241m.\u001b[39mNULL:\n\u001b[1;32m   1263\u001b[0m     \u001b[38;5;66;03m# get the actual error code\u001b[39;00m\n\u001b[1;32m   1264\u001b[0m     err \u001b[38;5;241m=\u001b[39m _snd\u001b[38;5;241m.\u001b[39msf_error(file_ptr)\n\u001b[0;32m-> 1265\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LibsndfileError(err, prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError opening \u001b[39m\u001b[38;5;132;01m{0!r}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname))\n\u001b[1;32m   1266\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode_int \u001b[38;5;241m==\u001b[39m _snd\u001b[38;5;241m.\u001b[39mSFM_WRITE:\n\u001b[1;32m   1267\u001b[0m     \u001b[38;5;66;03m# Due to a bug in libsndfile version <= 1.0.25, frames != 0\u001b[39;00m\n\u001b[1;32m   1268\u001b[0m     \u001b[38;5;66;03m# when opening a named pipe in SFM_WRITE mode.\u001b[39;00m\n\u001b[1;32m   1269\u001b[0m     \u001b[38;5;66;03m# See http://github.com/erikd/libsndfile/issues/77.\u001b[39;00m\n\u001b[1;32m   1270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info\u001b[38;5;241m.\u001b[39mframes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mLibsndfileError\u001b[0m: Error opening 'melody_4_val0_aro10.wav': System error."
     ]
    }
   ],
   "source": [
    "import os\n",
    "# output_dir = c.get_output_directory_path\n",
    "# print(output_dir)\n",
    "output_dir = \"../data/output/20250508_053837/\"\n",
    "\n",
    "music_genre = 'Electronic music'\n",
    "mg = MusicGenFromMelody(output_dir, duration=10)\n",
    "\n",
    "wav_files = [f for f in os.listdir(output_dir) if f.lower().endswith('.wav')] # iterate for all wav files in specified directory\n",
    "for idx, wav_file in enumerate(wav_files):\n",
    "    wav_path = os.path.join(output_dir, wav_file)\n",
    "    mg.music_gen_from_melody(wav_path, f\"{music_genre}, {emotion_array[idx]}\", idx)\n",
    "# mg.music_gen_from_melody(melody_path=\"../data/output/20250508_053837/melody_6_val0_aro100.wav\", description=f\"{music_genre}, {emotion_array[5]}\", idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0672ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # generate prompt\n",
    "# music_genre = 'Classical music'\n",
    "# prompt_array = convert_element_to_aspect.get_prompt_text(valence_array, arousal_array, music_genre)\n",
    " \n",
    "# # # export prompt as text file\n",
    "# pe = PromptExporter(prompt_array)\n",
    "# pe.export_prompt_as_text()\n",
    "\n",
    "# # combine 2 array for the next use\n",
    "# val_aro_array = np.vstack((valence_array, arousal_array))\n",
    "\n",
    "# mg = MusicGenerater(model_size='small', duration_in_s=20)\n",
    "# mg.generate_music_from_prompt(prompt_array, val_aro_array, music_genre, is_save_to_files=True, dir_path=\"../data/output\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-musicalization-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
