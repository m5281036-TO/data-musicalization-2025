{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e359b47f-d9ab-480c-a020-b8656843d2c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/takuto/data-musicalization-new/data-musicalization-venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from FileLoader import FileLoader\n",
    "from DisplayHistogram import DisplayHistogram\n",
    "from RandomDataPicker import RandomDataPicker\n",
    "from ConvertElementToAspect import ConvertElementToAspect\n",
    "from PromptExporter import PromptExporter\n",
    "from CreateChordsAndMelody import CreateChordsAndMelody\n",
    "from ValenceArousalToEmotion import ValenceArousalToEmotion\n",
    "from MusicGenFromMelody import MusicGenFromMelody\n",
    "from MusicGenerater import MusicGenerater\n",
    "from CreateCrossfade import CreateCrossFade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae5be2f",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3053429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File loaded successfully: ../data/weather_test_data_202505.csv \n",
      "elements in loaded data: ['Unnamed: 0', 'sunlight', 'temperature', 'precipitation', 'weather']\n",
      "rows in data: 9\n"
     ]
    }
   ],
   "source": [
    "# specify file name here\n",
    "weather_data_filepath = \"../data/weather_test_data_202505.csv\"\n",
    "\n",
    "file_loader = FileLoader(weather_data_filepath) # create instance\n",
    "\n",
    "# load data from specified csv file\n",
    "loaded_data = file_loader.load_csv()\n",
    "# print(loaded_data)\n",
    "\n",
    "elements = file_loader.get_elements()\n",
    "rows = file_loader.get_rows()\n",
    "print(f\"elements in loaded data: {elements}\\nrows in data: {rows}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9519c8ab",
   "metadata": {},
   "source": [
    "## Visualization of Loaded Data (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b97df2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display_histogram = DisplayHistogram(loaded_data)\n",
    "# display_histogram.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9cfe05",
   "metadata": {},
   "source": [
    "## Randomly Pick Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29655bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_data_picker = RandomDataPicker(loaded_data)\n",
    "# random_df = random_data_picker.get_random_data_samples(6, exclude_duplicate='precipitation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b99978e",
   "metadata": {},
   "source": [
    "## Assign Data Parameters to Musical Aspects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b167611e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'precipitation' [20, 0] is mapped to 'valence [0, 100]' (inverted)\n",
      "[90, 90, 90, 0, 0, 0, -100, -100, -100]\n",
      "'temperature' [20, 10] is mapped to 'arousal [0, 100]'\n",
      "[10, 50, 100, 10, 50, 100, 10, 50, 100]\n",
      "['extremely contentment', 'extremely happy and joyful', 'extremely happy and joyful', 'extremely happy and joyful', 'happy and joyful', 'extremely happy and joyful', 'extremely sad', 'extremely angery or fearful', 'extremely angery or fearful']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "convert_element_to_aspect = ConvertElementToAspect(loaded_data)\n",
    "\n",
    "# convert valence [-100, 100]\n",
    "valence_array = convert_element_to_aspect.convert_element_to_valence('precipitation', 20, 0, isInverted=True)\n",
    "print(valence_array)\n",
    "# convert valence [0, 100]\n",
    "arousal_array = convert_element_to_aspect.convert_element_to_arousal('temperature', 20, 10)\n",
    "print(arousal_array)\n",
    "\n",
    "e = ValenceArousalToEmotion(valence_array, arousal_array)\n",
    "emotion_array = e.convert_valencea_arousal_to_emotion()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d473a185",
   "metadata": {},
   "source": [
    "## Generate Music from Prompt\n",
    "### Generate Melody Files (MIDI and WAV Files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce3c1227",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# c = CreateChordsAndMelody()\n",
    "# c.create_midi_and_wav(valence_array, arousal_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6386a414",
   "metadata": {},
   "source": [
    "### Generate Music Based on Melody Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbe1cf3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/takuto/data-musicalization-new/data-musicalization-venv/lib/python3.9/site-packages/audiocraft/models/musicgen.py:80: UserWarning: MusicGen pretrained model relying on deprecated checkpoint mapping. Please use full pre-trained id instead: facebook/musicgen-melody\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m music_genre \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mElectronic music\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      5\u001b[0m mugicgen_out_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(melody_dir, music_genre)\n\u001b[0;32m----> 7\u001b[0m mg \u001b[38;5;241m=\u001b[39m \u001b[43mMusicGenFromMelody\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmelody_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmugicgen_out_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mduration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m melody_files \u001b[38;5;241m=\u001b[39m [f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(melody_dir) \u001b[38;5;28;01mif\u001b[39;00m f\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.wav\u001b[39m\u001b[38;5;124m'\u001b[39m)] \u001b[38;5;66;03m# iterate for all wav files in specified directory\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, wav_file \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(melody_files):\n",
      "File \u001b[0;32m~/data-musicalization-new/src/MusicGenFromMelody.py:23\u001b[0m, in \u001b[0;36mMusicGenFromMelody.__init__\u001b[0;34m(self, input_dir, output_dir, duration)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_dir \u001b[38;5;241m=\u001b[39m input_dir\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_dir \u001b[38;5;241m=\u001b[39m output_dir\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mMusicGen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmelody\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mset_generation_params(duration\u001b[38;5;241m=\u001b[39mduration)\n",
      "File \u001b[0;32m~/data-musicalization-new/data-musicalization-venv/lib/python3.9/site-packages/audiocraft/models/musicgen.py:85\u001b[0m, in \u001b[0;36mMusicGen.get_pretrained\u001b[0;34m(name, device)\u001b[0m\n\u001b[1;32m     80\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m     81\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMusicGen pretrained model relying on deprecated checkpoint mapping. \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m     82\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease use full pre-trained id instead: facebook/musicgen-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     83\u001b[0m     name \u001b[38;5;241m=\u001b[39m _HF_MODEL_CHECKPOINTS_MAP[name]\n\u001b[0;32m---> 85\u001b[0m lm \u001b[38;5;241m=\u001b[39m \u001b[43mload_lm_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m compression_model \u001b[38;5;241m=\u001b[39m load_compression_model(name, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mself_wav\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m lm\u001b[38;5;241m.\u001b[39mcondition_provider\u001b[38;5;241m.\u001b[39mconditioners:\n",
      "File \u001b[0;32m~/data-musicalization-new/data-musicalization-venv/lib/python3.9/site-packages/audiocraft/models/loaders.py:114\u001b[0m, in \u001b[0;36mload_lm_model\u001b[0;34m(file_or_url_or_id, device, cache_dir)\u001b[0m\n\u001b[1;32m    112\u001b[0m _delete_param(cfg, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconditioners.args.merge_text_conditions_p\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    113\u001b[0m _delete_param(cfg, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconditioners.args.drop_desc_p\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 114\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mbuilders\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_lm_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(pkg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_state\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    116\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m~/data-musicalization-new/data-musicalization-venv/lib/python3.9/site-packages/audiocraft/models/builders.py:110\u001b[0m, in \u001b[0;36mget_lm_model\u001b[0;34m(cfg)\u001b[0m\n\u001b[1;32m    108\u001b[0m     pattern_provider \u001b[38;5;241m=\u001b[39m get_codebooks_pattern_provider(n_q, codebooks_pattern_cfg)\n\u001b[1;32m    109\u001b[0m     lm_class \u001b[38;5;241m=\u001b[39m MagnetLMModel \u001b[38;5;28;01mif\u001b[39;00m cfg\u001b[38;5;241m.\u001b[39mlm_model \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransformer_lm_magnet\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m LMModel\n\u001b[0;32m--> 110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlm_class\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpattern_provider\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpattern_provider\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcondition_provider\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcondition_provider\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfuser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfuser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcfg_dropout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg_prob\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcfg_coef\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg_coef\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattribute_dropout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattribute_dropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(cfg\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected LM model \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcfg\u001b[38;5;241m.\u001b[39mlm_model\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/data-musicalization-new/data-musicalization-venv/lib/python3.9/site-packages/audiocraft/models/lm.py:164\u001b[0m, in \u001b[0;36mLMModel.__init__\u001b[0;34m(self, pattern_provider, condition_provider, fuser, n_q, card, dim, num_heads, hidden_scale, norm, norm_first, emb_lr, bias_proj, weight_init, depthwise_init, zero_bias_init, cfg_dropout, cfg_coef, attribute_dropout, two_step_cfg, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpattern_provider \u001b[38;5;241m=\u001b[39m pattern_provider\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtwo_step_cfg \u001b[38;5;241m=\u001b[39m two_step_cfg\n\u001b[0;32m--> 164\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memb \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mModuleList([ScaledEmbedding(embed_dim, dim, lr\u001b[38;5;241m=\u001b[39memb_lr) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_q)])\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactivation\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[1;32m    166\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactivation\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m get_activation_fn(kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactivation\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/data-musicalization-new/data-musicalization-venv/lib/python3.9/site-packages/audiocraft/models/lm.py:164\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpattern_provider \u001b[38;5;241m=\u001b[39m pattern_provider\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtwo_step_cfg \u001b[38;5;241m=\u001b[39m two_step_cfg\n\u001b[0;32m--> 164\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memb \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mModuleList([\u001b[43mScaledEmbedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43memb_lr\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_q)])\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactivation\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[1;32m    166\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactivation\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m get_activation_fn(kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactivation\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/data-musicalization-new/data-musicalization-venv/lib/python3.9/site-packages/audiocraft/models/lm.py:101\u001b[0m, in \u001b[0;36mScaledEmbedding.__init__\u001b[0;34m(self, lr, *args, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 101\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr \u001b[38;5;241m=\u001b[39m lr\n",
      "File \u001b[0;32m~/data-musicalization-new/data-musicalization-venv/lib/python3.9/site-packages/torch/nn/modules/sparse.py:144\u001b[0m, in \u001b[0;36mEmbedding.__init__\u001b[0;34m(self, num_embeddings, embedding_dim, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse, _weight, _freeze, device, dtype)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m=\u001b[39m Parameter(torch\u001b[38;5;241m.\u001b[39mempty((num_embeddings, embedding_dim), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfactory_kwargs),\n\u001b[1;32m    143\u001b[0m                             requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m _freeze)\n\u001b[0;32m--> 144\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(_weight\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m [num_embeddings, embedding_dim], \\\n\u001b[1;32m    147\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mShape of weight does not match num_embeddings and embedding_dim\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m~/data-musicalization-new/data-musicalization-venv/lib/python3.9/site-packages/torch/nn/modules/sparse.py:153\u001b[0m, in \u001b[0;36mEmbedding.reset_parameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mreset_parameters\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 153\u001b[0m     \u001b[43minit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormal_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fill_padding_idx_with_zero()\n",
      "File \u001b[0;32m~/data-musicalization-new/data-musicalization-venv/lib/python3.9/site-packages/torch/nn/init.py:155\u001b[0m, in \u001b[0;36mnormal_\u001b[0;34m(tensor, mean, std)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39moverrides\u001b[38;5;241m.\u001b[39mhas_torch_function_variadic(tensor):\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39moverrides\u001b[38;5;241m.\u001b[39mhandle_torch_function(normal_, (tensor,), tensor\u001b[38;5;241m=\u001b[39mtensor, mean\u001b[38;5;241m=\u001b[39mmean, std\u001b[38;5;241m=\u001b[39mstd)\n\u001b[0;32m--> 155\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_no_grad_normal_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstd\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/data-musicalization-new/data-musicalization-venv/lib/python3.9/site-packages/torch/nn/init.py:19\u001b[0m, in \u001b[0;36m_no_grad_normal_\u001b[0;34m(tensor, mean, std)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_no_grad_normal_\u001b[39m(tensor, mean, std):\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 19\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormal_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstd\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "# melody_dir = c.get_output_directory_path\n",
    "melody_dir = \"../data/output/20250508_053837/input_melody/sin\"\n",
    "music_genre = 'Electronic music'\n",
    "mugicgen_out_dir = os.path.join(melody_dir, music_genre)\n",
    "\n",
    "mg = MusicGenFromMelody(melody_dir, mugicgen_out_dir, duration=20)\n",
    "\n",
    "melody_files = [f for f in os.listdir(melody_dir) if f.lower().endswith('.wav')] # iterate for all wav files in specified directory\n",
    "for idx, wav_file in enumerate(melody_files):\n",
    "    wav_path = os.path.join(melody_dir, wav_file)\n",
    "    mg.music_gen_from_melody(wav_path, f\"{music_genre}, {emotion_array[idx]}\", idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1e7109",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mugicgen_out_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# create cross fade\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mmugicgen_out_dir\u001b[49m)\n\u001b[1;32m      3\u001b[0m crossfade_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/output/20250508_053837/output_music/from_saw/Electronic music\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m cf \u001b[38;5;241m=\u001b[39m CreateCrossFade(mugicgen_out_dir, fade_duration_ms\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5000\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mugicgen_out_dir' is not defined"
     ]
    }
   ],
   "source": [
    "# create cross fade\n",
    "crossfade_dir = \"../data/output/20250508_053837/output_music/from_saw/Electronic music\"\n",
    "cf = CreateCrossFade(crossfade_dir, fade_duration_ms=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0672ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # generate prompt\n",
    "# music_genre = 'Classical music'\n",
    "# prompt_array = convert_element_to_aspect.get_prompt_text(valence_array, arousal_array, music_genre)\n",
    " \n",
    "# # # export prompt as text file\n",
    "# pe = PromptExporter(prompt_array)\n",
    "# pe.export_prompt_as_text()\n",
    "\n",
    "# # combine 2 array for the next use\n",
    "# val_aro_array = np.vstack((valence_array, arousal_array))\n",
    "\n",
    "# mg = MusicGenerater(model_size='small', duration_in_s=20)\n",
    "# mg.generate_music_from_prompt(prompt_array, val_aro_array, music_genre, is_save_to_files=True, dir_path=\"../data/output\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-musicalization-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
