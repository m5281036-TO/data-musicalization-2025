{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e359b47f-d9ab-480c-a020-b8656843d2c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/takuto/data-musicalization-new/data-musicalization-venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from FileLoader import FileLoader\n",
    "from DisplayHistogram import DisplayHistogram\n",
    "from RandomDataPicker import RandomDataPicker\n",
    "from ConvertElementToAspect import ConvertElementToAspect\n",
    "from PromptExporter import PromptExporter\n",
    "from CreateChordsAndMelody import CreateChordsAndMelody\n",
    "from ValenceArousalToEmotion import ValenceArousalToEmotion\n",
    "from MusicGenFromMelody import MusicGenFromMelody\n",
    "from MusicGenerater import MusicGenerater"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae5be2f",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3053429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File loaded successfully: ../data/weather_test_data_202505.csv \n",
      "elements in loaded data: ['Unnamed: 0', 'sunlight', 'temperature', 'precipitation', 'weather']\n",
      "rows in data: 9\n"
     ]
    }
   ],
   "source": [
    "# specify file name here\n",
    "weather_data_filepath = \"../data/weather_test_data_202505.csv\"\n",
    "\n",
    "file_loader = FileLoader(weather_data_filepath) # create instance\n",
    "\n",
    "# load data from specified csv file\n",
    "loaded_data = file_loader.load_csv()\n",
    "# print(loaded_data)\n",
    "\n",
    "elements = file_loader.get_elements()\n",
    "rows = file_loader.get_rows()\n",
    "print(f\"elements in loaded data: {elements}\\nrows in data: {rows}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9519c8ab",
   "metadata": {},
   "source": [
    "## Visualization of Loaded Data (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b97df2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display_histogram = DisplayHistogram(loaded_data)\n",
    "# display_histogram.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9cfe05",
   "metadata": {},
   "source": [
    "## Randomly Pick Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29655bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_data_picker = RandomDataPicker(loaded_data)\n",
    "# random_df = random_data_picker.get_random_data_samples(6, exclude_duplicate='precipitation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b99978e",
   "metadata": {},
   "source": [
    "## Assign Data Parameters to Musical Aspects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b167611e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'precipitation' [20, 0] is mapped to 'valence [0, 100]' (inverted)\n",
      "[90, 90, 90, 0, 0, 0, -100, -100, -100]\n",
      "'temperature' [20, 10] is mapped to 'arousal [0, 100]'\n",
      "[10, 50, 100, 10, 50, 100, 10, 50, 100]\n",
      "['extremely contentment', 'extremely happy and joyful', 'extremely happy and joyful', 'extremely happy and joyful', 'happy and joyful', 'extremely happy and joyful', 'extremely sad', 'extremely angery or fearful', 'extremely angery or fearful']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "convert_element_to_aspect = ConvertElementToAspect(loaded_data)\n",
    "\n",
    "# convert valence [-100, 100]\n",
    "valence_array = convert_element_to_aspect.convert_element_to_valence('precipitation', 20, 0, isInverted=True)\n",
    "print(valence_array)\n",
    "# convert valence [0, 100]\n",
    "arousal_array = convert_element_to_aspect.convert_element_to_arousal('temperature', 20, 10)\n",
    "print(arousal_array)\n",
    "\n",
    "e = ValenceArousalToEmotion(valence_array, arousal_array)\n",
    "emotion_array = e.convert_valencea_arousal_to_emotion()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d473a185",
   "metadata": {},
   "source": [
    "## Generate Music from Prompt\n",
    "### Generate Melody Files (MIDI and WAV Files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce3c1227",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# c = CreateChordsAndMelody()\n",
    "# c.create_midi_and_wav(valence_array, arousal_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6386a414",
   "metadata": {},
   "source": [
    "### Generate Music Based on Melody Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbe1cf3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MusicGen output file saved: ../data/output/20250508_053837/musicgen_out/melody_9_val-100_aro100.wav\n",
      "-------- Generating --------\n",
      "prompt: Electronic music, extremely contentment\n",
      "melody: ../data/output/20250508_053837/melody_9_val-100_aro100.wav\n",
      "\n",
      "\n",
      "model created, generating audio...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MusicGenFromMelody' object has no attribute 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, wav_file \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(melody_files):\n\u001b[1;32m     11\u001b[0m     wav_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(melody_dir, wav_file)\n\u001b[0;32m---> 12\u001b[0m     \u001b[43mmg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmusic_gen_from_melody\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwav_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmusic_genre\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m, \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43memotion_array\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# idx = 0\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# mg.music_gen_from_melody(\"../data/output/20250508_053837/melody_6_val0_aro100.wav\", f\"{music_genre}, {emotion_array[5]}\", idx)\u001b[39;00m\n",
      "File \u001b[0;32m~/data-musicalization-new/src/MusicGenFromMelody.py:38\u001b[0m, in \u001b[0;36mMusicGenFromMelody.music_gen_from_melody\u001b[0;34m(self, melody_path, description, idx)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# generates using the melody from the given audio and the provided descriptions.\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mmodel created, generating audio...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 38\u001b[0m wav \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mgenerate_with_chroma([description], melody, sr)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# set wav dimension\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wav\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m wav\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MusicGenFromMelody' object has no attribute 'model'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# melody_dir = c.get_output_directory_path\n",
    "melody_dir = \"../data/output/20250508_053837/\"\n",
    "mugicgen_out_dir = os.path.join(melody_dir, \"musicgen_out\")\n",
    "\n",
    "music_genre = 'Electronic music'\n",
    "mg = MusicGenFromMelody(melody_dir, mugicgen_out_dir, duration=20)\n",
    "\n",
    "melody_files = [f for f in os.listdir(melody_dir) if f.lower().endswith('.wav')] # iterate for all wav files in specified directory\n",
    "for idx, wav_file in enumerate(melody_files):\n",
    "    wav_path = os.path.join(melody_dir, wav_file)\n",
    "    mg.music_gen_from_melody(wav_path, f\"{music_genre}, {emotion_array[idx]}\", idx)\n",
    "\n",
    "# idx = 0\n",
    "# mg.music_gen_from_melody(\"../data/output/20250508_053837/melody_6_val0_aro100.wav\", f\"{music_genre}, {emotion_array[5]}\", idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0672ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # generate prompt\n",
    "# music_genre = 'Classical music'\n",
    "# prompt_array = convert_element_to_aspect.get_prompt_text(valence_array, arousal_array, music_genre)\n",
    " \n",
    "# # # export prompt as text file\n",
    "# pe = PromptExporter(prompt_array)\n",
    "# pe.export_prompt_as_text()\n",
    "\n",
    "# # combine 2 array for the next use\n",
    "# val_aro_array = np.vstack((valence_array, arousal_array))\n",
    "\n",
    "# mg = MusicGenerater(model_size='small', duration_in_s=20)\n",
    "# mg.generate_music_from_prompt(prompt_array, val_aro_array, music_genre, is_save_to_files=True, dir_path=\"../data/output\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-musicalization-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
